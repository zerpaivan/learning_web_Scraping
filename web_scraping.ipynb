{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs =BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_all y get_tex()\n",
    "**find_all(etiqueta, atributos)**: retorna todo los elementos que coincidan con los filtros.\n",
    "\n",
    "**find()**: retorna solo el primer elementos que coincide con los filtros.\n",
    "\n",
    "**get_text()**: retorna solo el texto, sin etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Artículos\n",
      "0 Artículos\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://gamaenlinea.com/VIVERES/Aceites-y-aderezos/Mayonesas/MAYONESA-NATURAL-HEINZ-370-GR/p/10034430')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "namelist = bs.find_all('span', {'class':'nav-items-total'})\n",
    "for name in namelist:\n",
    "    print(name.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script para paginas que tienen proteccion contra el agente de usuario de python\n",
    "\n",
    "Una posible solucion es cambiar el User-Agent para que python se parezca a un navegador como Mozilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>HUEVOS EN ESTUCHE DE 12 UNIDADES</title>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://vallearriba.elplazas.com/huevos-en-estuche-de-12und.html'\n",
    "hdr = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)' }\n",
    "\n",
    "req = urllib.request.Request(url, headers=hdr)\n",
    "response = urllib.request.urlopen(req)\n",
    "bs = BeautifulSoup(response, 'html.parser')\n",
    "print(bs.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de exepciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1x.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "servidor no encontrado  <urlopen error [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('https://garmaenlinea.com/BEBIDAS/Cervezas/Nacionales/CERVEZA-POLAR-TIPO-PILSEN-BOTELLA-0%2C355-LT/p/40005236')\n",
    "except HTTPError as e:\n",
    "    print('A ocurrido un error', e)\n",
    "except URLError as e:\n",
    "    print('servidor no encontrado ', e)\n",
    "else:\n",
    "    print('Bien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server could not be found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('https://pythonscrapingthisurldoesnotexist.com')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('The server could not be found!')\n",
    "else:\n",
    "    print('It Worked')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excepciones en la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta no encontrada 'NoneType' object has no attribute 'Otraetiqueta'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    badcontent = bs.etiquetaNoExiste.Otraetiqueta\n",
    "except AttributeError as e:\n",
    "    print('Etiqueta no encontrada', e)\n",
    "else:\n",
    "    if badcontent == None:\n",
    "        print('Etiqueta no encontrada')\n",
    "    else:\n",
    "        print(badcontent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "        title = bs.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    \n",
    "    return title\n",
    "\n",
    "title = getTitle('http://www.pythonscraping.com/pages/page1.html')\n",
    "if title == None:\n",
    "    print('Title could not be found')\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "print(bs.find_all('div'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced HTML Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *find_all(etiqueta, etiquetaAtributos)*: funcion que se utiliza para buscar a traves de un archivo y retornar los elementos que coincidan con sus filtros\n",
    "- *find*: retorna solo el primer elemnto que conincide con los filtros\n",
    "- *get_text()*: funcion que retorna solo el texto de un objeto beautifulSoup sin las etiquetas o tags\n",
    "\n",
    ".find_all(['h1','h2','h3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retornar una lista de varias etiquetas\n",
    "#.find_all(['h1','h2','h3'])\n",
    "\n",
    "# filtrando por etiqueta, y varios atributos\n",
    "#.find_all('span', {'class': {'grenn', 'red'}})\n",
    "\n",
    "# busqueda por texto\n",
    "#.find_all(string='the text')\n",
    "\n",
    "# filtrar por keywords\n",
    "#.find_all(id='cosa', class_='algo') # class con _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://www.pythonscraping.com/pages/warandpeace.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "# busqueda por etiqueta y atributo\n",
    "nameList = bs.find_all('span', {'class':'green'})\n",
    "\n",
    "for name in nameList:\n",
    "    print(name.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar etiquetas basado en la ubicacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chidren() y descendants()\n",
    "El metodo children devuelve una lista de todos los hijos directos de una etiqueta html, mientras que descendants() devuelve una lista con todos los decendiendes de la etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n",
      "1 <tr><th>\n",
      "Item Title\n",
      "</th><th>\n",
      "Description\n",
      "</th><th>\n",
      "Cost\n",
      "</th><th>\n",
      "Image\n",
      "</th></tr>\n",
      "2 \n",
      "\n",
      "3 <tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "4 \n",
      "\n",
      "5 <tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "6 \n",
      "\n",
      "7 <tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "8 \n",
      "\n",
      "9 <tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "10 \n",
      "\n",
      "11 <tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://www.pythonscraping.com/pages/page3.html')\n",
    "\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "for e, child in enumerate(bs.find('table', {'id':'giftList'}).children):\n",
    "    print(e, child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next_sibling y next_siblings()\n",
    "Permite obtener el siguiente hermano(s) de un elemento del arbol de un documento HTML o XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "for n, sibling in enumerate(bs.find('table', {'id':'giftList'}).tr.next_sibling):\n",
    "    print(n, sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## previous_siblings\n",
    "Permite obtener los hermanos anteriores de un elemento del documento html oxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<p id=\"2\">Este es el segundo párrafo.</p>\n",
      "\n",
      "\n",
      "<p id=\"3\">Este es el tercer párrafo.</p>\n",
      "\n",
      "\n",
      "---------------------------\n",
      "\n",
      "\n",
      "<p id=\"0\">Este es el parrafo cero</p>\n",
      "\n",
      "\n",
      "<h1>Título</h1>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ejemplo\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Prueba</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Título</h1>\n",
    "    <p id=0>Este es el parrafo cero</p>\n",
    "    <p id=1>Este es el primer párrafo.</p>\n",
    "    <p id=2>Este es el segundo párrafo.</p>\n",
    "    <p id=3>Este es el tercer párrafo.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Obtenemos la primera etiqueta p\n",
    "primer_p = soup.find('p',{'id':1})\n",
    "\n",
    "# Recorremos todos los hermanos siguientes de la primera etiqueta p\n",
    "for hermano in primer_p.next_siblings:\n",
    "    print(hermano)\n",
    "\n",
    "# elementos previos\n",
    "print('---------------------------')\n",
    "for hermano in primer_p.previous_siblings:\n",
    "    print(hermano)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', <p>Ubicacion: Centro de San Juan</p>, '\\n', <li>el castrero</li>, '\\n', <p>Ubicacion: Sureste</p>, '\\n', <li>la puerta del llano</li>, '\\n', <p>Ubicacion: Norte</p>, '\\n']\n",
      "0 <p>Ubicacion: Centro de San Juan</p>\n",
      "1 <li>el castrero</li>\n",
      "2 <p>Ubicacion: Sureste</p>\n",
      "3 <li>la puerta del llano</li>\n",
      "4 <p>Ubicacion: Norte</p>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = open('index.html','r')\n",
    "# html = urlopen('index.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "sitiosTuristicos = bs.find('li')\n",
    "# print(sitiosTuristicos)\n",
    "print(list(sitiosTuristicos.next_siblings))\n",
    "\n",
    "result =[]\n",
    "for h in sitiosTuristicos.next_siblings:\n",
    "    if h != '\\n':\n",
    "        result.append(h)\n",
    "\n",
    "for n, hijo in enumerate(result):\n",
    "    print(n, hijo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parent and parents\n",
    "Permiten obtener los elementos que estan por encima de otro elemnto del documento html o xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ul\n",
      "div\n",
      "[document]\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<div id=\"pages\">\n",
    "  <ul>\n",
    "    <li class=\"active\"><a href=\"example.com\">Example</a></li>\n",
    "    <li><a href=\"example.com\">Example</a></li>\n",
    "    <li><a href=\"example1.com\">Example 1</a></li>\n",
    "    <li><a href=\"example2.com\">Example 2</a></li>\n",
    "  </ul>\n",
    "</div>\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "page = soup.find('li', {'class', 'active'})\n",
    "padres = page.parents\n",
    "for p in padres:\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$15.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "print(bs.find('img', {'src':'../img/gifts/img1.jpg'}).parent.previous_sibling.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo Pruebas\n",
    "\n",
    "investigar:\n",
    "metodo name\n",
    "metodo prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"from-price-value\" style=\"font-weight: bold;\">Total Ref. 2,15</div>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import  urlopen\n",
    "from bs4 import  BeautifulSoup\n",
    "html = urlopen('https://gamaenlinea.com/VIVERES/Panes/Salados/PAN-DE-SANDWICH-BLANCO-HOLSUM-420-GR/p/10034381')\n",
    "\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "precio = bs.find('div', {'class':'from-price-value'})\n",
    "print(precio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
